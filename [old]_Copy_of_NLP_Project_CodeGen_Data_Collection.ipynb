{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJoiGJdSqOSl",
        "outputId": "7228bd0a-a8f4-4f63-a17d-bab3ecbd87d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_metric\n",
            "  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rouge_metric\n",
            "Successfully installed rouge_metric-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install rouge_metric\n",
        "!pip install transformers\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cd drive/Shareddrives/COS484FinalProject/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8coBKzNA9kge"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "import collections\n",
        "import json\n",
        "import os\n",
        "import regex\n",
        "\n",
        "\n",
        "\n",
        "class MBPPGoogleDataset(object):\n",
        "    def __init__(self, path='/content/drive/Shareddrives/COS484FinalProject/data/mbpp/mbpp.jsonl', mode='function_name'):\n",
        "        raw_data = sorted([json.loads(x) for x in open(path)], key=lambda x: x['task_id'])\n",
        "        for i, data_item in enumerate(raw_data):\n",
        "            assert data_item['task_id'] == i + 1\n",
        "        self.raw_data = collections.defaultdict()\n",
        "        self.mode = mode\n",
        "        # 374 for training, 100 heldout, 500 test\n",
        "        self.raw_data['train'] = raw_data[:10] + raw_data[510:]\n",
        "        self.raw_data['test'] = raw_data[10:510]\n",
        "        # data for codex collector, in input-output-info format\n",
        "        self.data = collections.defaultdict()\n",
        "        for split in self.raw_data:\n",
        "            self.data[split] = self.extract_data(self.raw_data[split], mode)\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_data(raw_data, mode):\n",
        "        if mode == 'function_name':\n",
        "            get_function_name = lambda test_example: regex.match('assert [\\(]*([^\\(]+)\\(', test_example).group(1)\n",
        "            info = [get_function_name(x['test_list'][0]) for x in raw_data]\n",
        "        elif mode == 'assertion':\n",
        "            info = [x['test_list'][0] for x in raw_data]\n",
        "        elif mode == 'assertion-full':\n",
        "            info = [x['test_list'] for x in raw_data]\n",
        "        else:\n",
        "            raise Exception(f'Mode {mode} not supported.')\n",
        "        nls = [x['text'] for x in raw_data]\n",
        "        codes = [x['code'] for x in raw_data]\n",
        "        return list(zip(nls, codes, info))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUsWG9rWz3aH"
      },
      "outputs": [],
      "source": [
        "class Object(object):\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngI77YjtEVhO"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "import argparse\n",
        "import copy\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import signal\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from glob import glob\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import single_meteor_score as m\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import numpy as np\n",
        "from rouge_metric import PyRouge\n",
        "import nltk\n",
        "\n",
        "\n",
        "def codex_with_info(configs, dataset, prefixes, tokenizer, model):\n",
        "\n",
        "    def codex_greedy(prompt):\n",
        "        inputs = tokenizer(text=prompt, truncation=True,\n",
        "                           return_tensors=\"pt\").input_ids\n",
        "\n",
        "        sample = model.generate(inputs, temperature=0, output_scores=True,\n",
        "                                return_dict_in_generate=True, max_new_tokens=200, renormalize_logits=True)\n",
        "\n",
        "        output = tokenizer.decode(sample[0][0])\n",
        "\n",
        "        \n",
        "        # return this to get text\n",
        "        text = output[len(prompt):].split(\"</code>\", 1)[0]\n",
        "        #print(text)\n",
        "        return text, None, None\n",
        "    \n",
        "\n",
        "    def codex_sample(prompt):\n",
        "        inputs = tokenizer(text=prompt, truncation=True,\n",
        "                           return_tensors=\"pt\").input_ids\n",
        "\n",
        "        sample = model.generate(inputs, temperature=configs.temperature, output_scores=True,\n",
        "                                return_dict_in_generate=True, do_sample=True, max_new_tokens=200, renormalize_logits=True)\n",
        "\n",
        "        output = tokenizer.decode(sample[0][0])\n",
        "\n",
        "        # return this to get text\n",
        "        text = output[len(prompt):].split(\"</code>\", 1)[0]\n",
        "        # return this to return token ids\n",
        "        encoded = tokenizer.encode(text)\n",
        "        enc_len = len(encoded)\n",
        "\n",
        "        log_probs = np.zeros(enc_len)\n",
        "        # return this as final logs\n",
        "        for i in range(enc_len):\n",
        "            log_probs[i] = sample[1][i][0][encoded[i]]\n",
        "        #print(\"prediction:\")\n",
        "        #print(text)\n",
        "        #print(\"ids of predicted\")\n",
        "        #print(encoded)\n",
        "        #print(\"log_probs\")\n",
        "        #print(log_probs)\n",
        "        return text, encoded, log_probs.tolist()\n",
        "\n",
        "\n",
        "    prompt_prefix = ''.join([configs.prompt_template.format(\n",
        "        src=x[0], trg=x[1], info=x[2]) for x in prefixes])\n",
        "\n",
        "    # save folder\n",
        "    save_dir = f'{configs.output_path}/seed-{configs.seed}/{configs.n_prompts}-shot/{configs.mode}-{configs.temperature}/'\n",
        "    \n",
        "    os.system(f'mkdir -p {save_dir}')\n",
        "    # save configs and prefixes\n",
        "    if configs.rank == 0:\n",
        "        with open(f'{save_dir}/prefixes.json', 'w') as fout:\n",
        "            json.dump(prefixes, fout)\n",
        "            fout.close()\n",
        "        with open(f'{save_dir}/configs.pkl', 'wb') as fout:\n",
        "            pickle.dump(configs, fout)\n",
        "            fout.close()\n",
        "    ofname = f'{save_dir}/{configs.split}-{configs.rank}.jsonl'\n",
        "    # load checkpoint\n",
        "    if os.path.exists(ofname):\n",
        "        n_processed_examples = len(open(ofname).readlines())\n",
        "    else:\n",
        "        n_processed_examples = 0\n",
        "    pbar = tqdm(dataset)\n",
        "\n",
        "    with open(ofname, 'a') as fout:\n",
        "        for i, (src, trg, info) in enumerate(pbar):\n",
        "            if i < n_processed_examples:\n",
        "                continue\n",
        "            prompt = prompt_prefix + \\\n",
        "                configs.example_template.format(src=src, info=info)\n",
        "            #print(\"prompt\")\n",
        "            #print(prompt)\n",
        "            while True:\n",
        "                try:\n",
        "                    trg_prediction, tokens, logprobs = codex_greedy(\n",
        "                        prompt) if configs.mode == 'greedy' else codex_sample(prompt)\n",
        "                    time.sleep(2)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    \n",
        "                    print(e, flush=True)\n",
        "                    time.sleep(3)\n",
        "            try:\n",
        "\n",
        "                bleu_score = sentence_bleu([[ch for ch in trg]], [\n",
        "                                           ch for ch in trg_prediction])\n",
        "                #print(\"bleu score:\")\n",
        "                #print(bleu_score)\n",
        "            except:\n",
        "                bleu_score = 0\n",
        "            \n",
        "            try: \n",
        "\n",
        "                rouge_score = 0\n",
        "                rouge = PyRouge(rouge_n=(1,), rouge_l=True,\n",
        "                                    rouge_w=True, rouge_w_weight=1.2, rouge_s=True)\n",
        "                    # print(len(item['trg_prediction']))\n",
        "                    # print(len(item['reference']))\n",
        "                rouge_score = rouge.evaluate_tokenized(\n",
        "                        [[ch for ch in trg_prediction]], [[ch for ch in trg]])\n",
        "                #print(rouge_score)\n",
        "\n",
        "            except:\n",
        "                #print(\"fail rouge\")\n",
        "                rouge_score = 0\n",
        "\n",
        "            try: \n",
        "                \n",
        "                #print(\"meteor_score\")\n",
        "                \n",
        "                meteor_score = m([ch for ch in trg], [ch for ch in trg_prediction])\n",
        "                #print(meteor_score)\n",
        "                \n",
        "\n",
        "            except: \n",
        "               \n",
        "                # this works in colab but not vscode for some reason\n",
        "                \n",
        "                meteor_score = 0\n",
        "\n",
        "            print(\n",
        "                json.dumps(\n",
        "                    {\n",
        "                        'prompt': prompt,\n",
        "                        'src': src,\n",
        "                        'trg_prediction': trg_prediction,\n",
        "                        'reference': trg,\n",
        "                        'tokens': tokens,\n",
        "                        'logprobs': logprobs,\n",
        "                        'bleu': bleu_score,\n",
        "                        'rouge': rouge_score, \n",
        "                        'meteor': meteor_score\n",
        "                        \n",
        "                    }\n",
        "                ),\n",
        "                file=fout, flush=True\n",
        "            )\n",
        "            pbar.set_description(f'Process {configs.rank}')\n",
        "        fout.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "class CollectorWithInfo(object):\n",
        "    def __init__(self, dataset, tokenizer, model, rank):\n",
        "       #change here for arguments\n",
        "      self.configs = Object()\n",
        "      self.configs.output_path = \"/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp\"\n",
        "      self.configs.split = \"test\"\n",
        "      self.configs.seed = [1,2,3,4,5]\n",
        "      self.configs.temperature = [0.9]\n",
        "      self.configs.n_prompts = [3]\n",
        "      self.configs.n_samples = 5 # number of seeds multiplied by number of samples is the total number that we can look at\n",
        "      self.configs.mode = \"sample\"\n",
        "      self.configs.prompt_template = \"<info>{info}</info>\\n<text>{src}</text>\\n<code>{trg}</code>\\n\"\n",
        "      self.configs.example_template = \"<info>{info}</info>\\n<text>{src}</text>\\n<code>\"\n",
        "      self.configs.end_template = \"</code>\"\n",
        "      self.configs.shuffle_prefix = False\n",
        "      self.configs.saved_prefixes_path_template = None\n",
        "      self.configs.rank = rank\n",
        "      self.dataset = dataset\n",
        "      self.tokenizer = tokenizer\n",
        "      self.model = model\n",
        "\n",
        "    def __call__(self):\n",
        "\n",
        "        \n",
        "        configs = copy.deepcopy(self.configs)\n",
        "        \n",
        "        for seed in self.configs.seed:\n",
        "            for n_prompts in self.configs.n_prompts:\n",
        "                for temperature in self.configs.temperature:\n",
        "                    configs.n_prompts = n_prompts\n",
        "                    configs.seed = seed\n",
        "                    configs.temperature = temperature\n",
        "                    random.seed(configs.seed)\n",
        "                    if configs.saved_prefixes_path_template is not None:\n",
        "                        prefix_pool = list()\n",
        "                        for path in glob(configs.saved_prefixes_path_template, recursive=True):\n",
        "                            prefix_pool.extend(json.load(open(path)))\n",
        "                        prefix_pool = sorted(\n",
        "                            set([tuple(x) for x in prefix_pool]))\n",
        "                        prefixes = random.sample(\n",
        "                            prefix_pool, configs.n_prompts)\n",
        "                    else:\n",
        "                        prefixes = random.sample(\n",
        "                            self.dataset.data['train'], configs.n_prompts)\n",
        "                    if configs.shuffle_prefix:\n",
        "                        original_prefixes = copy.deepcopy(prefixes)\n",
        "                        while original_prefixes == prefixes:\n",
        "                            random.shuffle(prefixes)\n",
        "                    codex_with_info(\n",
        "                        configs, self.dataset.data[configs.split], prefixes, self.tokenizer, self.model)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "OqopLDsD3Ldx",
        "outputId": "41164680-8075-4164-9bf5-8372608f5f27"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a6f777f2eee6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# torch.set_default_tensor_type(torch.cuda.FloatTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salesforce/codegen-2B-mono\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \"Salesforce/codegen-2B-mono\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2631\u001b[0m         \u001b[0;31m# Check first if we are `from_pt`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCodeGenModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_embd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/codegen/modeling_codegen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_embd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd_pdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCodeGenBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs),\n\u001b[0m\u001b[1;32m    143\u001b[0m                                     requires_grad=not _freeze)\n\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "import torch # this line and next switch to GPU\n",
        "# torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-mono\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"Salesforce/codegen-2B-mono\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "Ofu92NrgEo3M",
        "outputId": "c78d2408-e332-479c-e523-769aae01d872"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c66f01b21b17>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmbpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMBPPGoogleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'assertion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'working with'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnewcollector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCollectorWithInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmbpp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MBPPGoogleDataset' is not defined"
          ]
        }
      ],
      "source": [
        "mbpp = MBPPGoogleDataset(mode = 'assertion')\n",
        "num_rank = range(1)\n",
        "for i in num_rank:\n",
        "  print('working with', i,' ---')\n",
        "  newcollector = CollectorWithInfo(mbpp, tokenizer, model, i)\n",
        "  newcollector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6GisntiUva1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkgQdr1RnBej",
        "outputId": "10ec486c-df1f-4662-b005-5f5d9b9b3df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKj2e1bUSdJQ",
        "outputId": "e2e36d19-6600-4533-c99d-fb9fe052a90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting data\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data) (4.4.2)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: data\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7244 sha256=46c562bac192061fc851549f9bd015c35f784ab672a04ac515f9079d0f0fdf17\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/e8/fa/e253c256048ea58d99a8abb5e751abb6a838af6f12887b5418\n",
            "Successfully built data\n",
            "Installing collected packages: funcsigs, data\n",
            "Successfully installed data-0.4 funcsigs-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM1VeRkkUnVy"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import regex\n",
        "import signal\n",
        "import subprocess\n",
        "import tempfile\n",
        "import threading\n",
        "from datasets import load_metric\n",
        "from glob import glob\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Command(object):\n",
        "    def __init__(self, cmd):\n",
        "        self.cmd = cmd\n",
        "        self.process = None\n",
        "\n",
        "    def run(self, timeout):\n",
        "        def target():\n",
        "            self.process = subprocess.Popen(self.cmd, shell=True, preexec_fn=os.setsid)\n",
        "            self.process.communicate()\n",
        "\n",
        "        thread = threading.Thread(target=target)\n",
        "        thread.start()\n",
        "\n",
        "        thread.join(timeout)\n",
        "        if thread.is_alive():\n",
        "            os.killpg(self.process.pid, signal.SIGTERM)\n",
        "            thread.join()\n",
        "        return self.process.returncode\n",
        "\n",
        "\n",
        "class PythonFunctionExecutor(object):\n",
        "    def __init__(self, function_content, function_call, timeout=10):\n",
        "        self.function_content = function_content\n",
        "        self.function_call = function_call\n",
        "        self.timeout = timeout\n",
        "\n",
        "    def __call__(self):\n",
        "        tempdir = tempfile.TemporaryDirectory()\n",
        "        with open(f'{tempdir.name}/code.py', 'w') as fout:\n",
        "            print(self.function_content, file=fout)\n",
        "            print(f'result = {self.function_call}', file=fout)\n",
        "            print(f'import pickle', file=fout)\n",
        "            print(f'pickle.dump(result, open(\"{tempdir.name}/execution_result.pkl\", \"wb\"))', file=fout)\n",
        "        command = Command(f'python {tempdir.name}/code.py >/dev/null 2>&1')\n",
        "        execution_status = command.run(timeout=self.timeout)\n",
        "        if execution_status == 0:\n",
        "            try:\n",
        "                execution_results = pickle.load(open(f'{tempdir.name}/execution_result.pkl', 'rb'))\n",
        "            except:\n",
        "                execution_results = None\n",
        "        else:\n",
        "            execution_results = None\n",
        "        tempdir.cleanup()\n",
        "        return execution_status, execution_results\n",
        "\n",
        "\n",
        "def execute_mbpp_google_folder(base_path):\n",
        "    # single assertion\n",
        "    print(\"hey\")\n",
        "    dataset = MBPPGoogleDataset(mode='assertion')\n",
        "    print(dataset)\n",
        "    !pwd\n",
        "    print(base_path)\n",
        "    for path in glob(f'{base_path}/*jsonl'):  # execute first assertion call\n",
        "        \n",
        "        if os.path.exists(path.replace('jsonl', 'exec.pkl')):\n",
        "            continue\n",
        "        split = os.path.basename(path).split('-')[0]\n",
        "        execution_results = list()\n",
        "        for i, line in enumerate(tqdm(open(path).readlines())):\n",
        "            assertion = dataset.data[split][i][-1]\n",
        "            command = regex.match(f'assert (.+)==.+', assertion).group(1)\n",
        "            item = json.loads(line)\n",
        "            python_function = item['trg_prediction']\n",
        "            executor = PythonFunctionExecutor(python_function, command)\n",
        "            execution_result = executor()\n",
        "            execution_results.append(execution_result)\n",
        "        with open(path.replace('jsonl', 'exec.pkl'), 'wb') as fout:\n",
        "            pickle.dump(execution_results, fout)\n",
        "    # multiple assertions (cheating)\n",
        "    dataset = MBPPGoogleDataset(mode='assertion-full')\n",
        "    for path in glob(f'{base_path}/*jsonl'):  # execute all assertion calls\n",
        "        if os.path.exists(path.replace('jsonl', 'execfull.pkl')):\n",
        "            continue\n",
        "        split = os.path.basename(path).split('-')[0]\n",
        "        execution_results = list()\n",
        "        for i, line in enumerate(tqdm(open(path).readlines())):\n",
        "            execution_result = list()\n",
        "            item = json.loads(line)\n",
        "            python_function = item['trg_prediction']\n",
        "            for assertion in dataset.data[split][i][-1]:\n",
        "                command = regex.match(f'assert (.+)==.+', assertion).group(1)\n",
        "                executor = PythonFunctionExecutor(python_function, command)\n",
        "                execution_result.append(executor())\n",
        "            execution_results.append(execution_result)\n",
        "        with open(path.replace('jsonl', 'execfull.pkl'), 'wb') as fout:\n",
        "            pickle.dump(execution_results, fout)\n",
        "    # multiple assertions (pass or fail)\n",
        "    for path in glob(f'{base_path}/*jsonl'):\n",
        "        if os.path.exists(path.replace('jsonl', 'execfullpass.pkl')):\n",
        "            continue\n",
        "        split = os.path.basename(path).split('-')[0]\n",
        "        execution_results = list()\n",
        "        for i, line in enumerate(tqdm(open(path).readlines())):\n",
        "            execution_result = list()\n",
        "            item = json.loads(line)\n",
        "            python_function = item['trg_prediction']\n",
        "            for assertion in dataset.data[split][i][-1]:\n",
        "                command = regex.match(f'assert (.+==.+)', assertion).group(1)\n",
        "                executor = PythonFunctionExecutor(python_function, f'({command})')\n",
        "                execution_result.append(executor())\n",
        "            execution_results.append(execution_result)\n",
        "        with open(path.replace('jsonl', 'execfullpass.pkl'), 'wb') as fout:\n",
        "            pickle.dump(execution_results, fout)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61E5v5QWaSJW",
        "outputId": "2e0cf651-d893-4ac6-9759-8770ae617f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey\n",
            "<__main__.MBPPGoogleDataset object at 0x7f947a2ad5d0>\n",
            "/content\n",
            "/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/seed-0/3-shot/sample-0.9\n"
          ]
        }
      ],
      "source": [
        "\n",
        "execute_mbpp_google_folder(\"/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/seed-0/3-shot/sample-0.9\")\n",
        "#exec.execute_mbpp_google_folder(\"mbr-2B/mbpp/seed-0/3-shot/sample-0.3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA4kLTIySZsF"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "from datasets import load_metric\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" dataset keys: src, trg_prediction, reference \"\"\"\n",
        "\n",
        "\n",
        "def evaluate_charbleu(dataset):\n",
        "    \n",
        "    bleu = load_metric('bleu')\n",
        "    predictions = [[ch for ch in item['trg_prediction']] for item in dataset]\n",
        "    references = [[[ch for ch in item['reference']]] for item in dataset]\n",
        "    return bleu.compute(predictions=predictions, references=references)\n",
        "\n",
        "\n",
        "\"\"\" dataset keys: src, trg_prediction, reference (only trg_prediction useful) \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_google_mbpp(dataset, reference_path, split='test', timeout=10, return_details=False):\n",
        "    references = MBPPGoogleDataset(reference_path)\n",
        "    assert len(dataset) == len(references.raw_data[split])\n",
        "    tempdir = tempfile.TemporaryDirectory()\n",
        "    passed_information = list()\n",
        "    pbar = tqdm(references.raw_data[split])\n",
        "    for i, item in enumerate(pbar):\n",
        "        if 'execution_result_full_pass' in dataset[i]:\n",
        "            passed_information.append(\n",
        "                int(all(x[1] == True for x in dataset[i]['execution_result_full_pass'])))\n",
        "        else:\n",
        "            test_cases = item['test_list']\n",
        "            test_setups = item['test_setup_code']\n",
        "            code = dataset[i]['trg_prediction']\n",
        "            # write code to file\n",
        "            with open(f'{tempdir.name}/code.py', 'w') as fout:\n",
        "                print(code, file=fout)\n",
        "                print(test_setups, file=fout)\n",
        "                for case in test_cases:\n",
        "                    print(case, file=fout)\n",
        "                fout.close()\n",
        "            command = Command(f'python {tempdir.name}/code.py >/dev/null 2>&1')\n",
        "            execution_result = (command.run(timeout=timeout) == 0)\n",
        "            passed_information.append(int(execution_result))\n",
        "        pbar.set_description(f'{sum(passed_information)} out of {i+1} passed.')\n",
        "    tempdir.cleanup()\n",
        "    if return_details:\n",
        "        return passed_information\n",
        "    else:\n",
        "        return sum(passed_information) / len(passed_information)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMmM029zXnGW",
        "outputId": "0342db56-e103-4dbe-fe57-2da132edc37a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn767HWGYDHp"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "\n",
        "import collections\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn import preprocessing\n",
        "from rouge_metric import PyRouge\n",
        "\n",
        "\"\"\" k sets of configs in separate paths, n * k choose 1 selector \"\"\"\n",
        "\n",
        "\n",
        "class MultiSampleSelector(object):\n",
        "    def __init__(self, paths, split='dev'):\n",
        "        self.paths = list(sorted(glob(paths, recursive=True))) if isinstance(\n",
        "            paths, str) else list(sorted(paths))\n",
        "        self.split = split\n",
        "        self.data = collections.defaultdict(list)\n",
        "        self.args = collections.defaultdict(list)\n",
        "        self.hyper_params = np.array([1.0, 100.0, 0.3])  # bleu, mbr, avg_log\n",
        "\n",
        "        for i, path in enumerate(self.paths):\n",
        "            self.args[i] = pickle.load(\n",
        "                open(f'{self.paths[0]}/configs.pkl', 'rb'))\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.jsonl'):\n",
        "                self.data[i, idx].extend(\n",
        "                    [json.loads(x) for x in open(f'{path}/{split}-{idx}.jsonl')])\n",
        "                idx += 1\n",
        "        for path_id, sample_id in self.data:\n",
        "            for item in self.data[path_id, sample_id]:\n",
        "                try:\n",
        "                    avg_logprob, sum_logprob = self.extract_logprob_stats(\n",
        "                        item, path_id)\n",
        "                    item['avg_logprob'] = avg_logprob\n",
        "                    item['sum_logprob'] = sum_logprob\n",
        "\n",
        "                except:\n",
        "                    item['avg_logprob'] = item['sum_logprob'] = 0\n",
        "                \n",
        "    def extract_logprob_stats(self, item, path_id):\n",
        "        current_seq = ''\n",
        "        extracted_position = None\n",
        "        for i, _ in enumerate(item['tokens']):\n",
        "            current_seq += item['tokens'][i]\n",
        "            if current_seq.find(item['trg_prediction']) != -1 and current_seq.find(self.args[path_id].end_template) != -1:\n",
        "                extracted_position = i + 1\n",
        "                break\n",
        "        logprobs = item['logprobs'][:extracted_position] if extracted_position is not None else item['logprobs']\n",
        "        # handle potential codex bug on positive log probability\n",
        "        logprobs = list(filter(lambda x: x < 0, logprobs))\n",
        "        return np.mean(logprobs), np.sum(logprobs)\n",
        "\n",
        "    def select(self, ids=None, key_extractor=lambda x: x['avg_logprob'], return_keys=False):\n",
        "        if ids is None:\n",
        "            ids = self.data.keys()\n",
        "        ids = list(sorted(ids))\n",
        "        print(f'Selecting Samples from IDs: {ids}', flush=True)\n",
        "        n_examples = len(self.data[ids[0]])\n",
        "        selected_examples = list()\n",
        "        sample_keys = collections.defaultdict(list)\n",
        "        for i in range(n_examples):\n",
        "            max_key = None\n",
        "            selected_item = None\n",
        "            for idx in ids:\n",
        "                item = self.data[idx][i]\n",
        "                key = key_extractor(item)\n",
        "                sample_keys[idx].append(key)\n",
        "                if max_key is None or key > max_key:\n",
        "                    max_key = key\n",
        "                    selected_item = item\n",
        "            assert selected_item is not None\n",
        "            selected_examples.append(selected_item)\n",
        "        if return_keys:\n",
        "            return selected_examples, sample_keys\n",
        "        else:\n",
        "            return selected_examples\n",
        "\n",
        "\n",
        "class ExecutionBasedMultiSampleSelector(MultiSampleSelector):\n",
        "    def __init__(self, paths, split='dev', execution_type=None):\n",
        "        super().__init__(paths, split=split)\n",
        "        self.execution_type = execution_type\n",
        "        for i, path in enumerate(self.paths):\n",
        "            if execution_type == 'mbpp':\n",
        "                execute_mbpp_google_folder(path)\n",
        "            else:\n",
        "                raise Exception(\n",
        "                    f'Execution type {execution_type} not supported.')\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.exec.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.exec.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result'] = execution_result\n",
        "                idx += 1\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.execfull.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.execfull.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result_full'] = execution_result\n",
        "                idx += 1\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.execfullpass.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.execfullpass.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result_full_pass'] = execution_result\n",
        "                idx += 1\n",
        "\n",
        "\n",
        "class IntraMultiSampleSelector(MultiSampleSelector):\n",
        "    def __init__(self, paths, split='dev'):\n",
        "        super().__init__(paths, split=split)\n",
        "        # to normalize log_avg,  just take e^x, to normalize mbr, we just take mbr/argument\n",
        "        # already try to have it normalized\n",
        "    # current and max = np array of normalized bleu, mbr, log_avg()\n",
        "\n",
        "    def greater(self, current, max):  # potentially make contextual\n",
        "\n",
        "        # diff is array of differences ranging from [-1, 1]\n",
        "\n",
        "        # multiply by weights in linear interpolation then sum\n",
        "        mult = np.dot(current - max, self.hyper_params)\n",
        "        # print(current)\n",
        "        # print(max)\n",
        "        # print(mult)\n",
        "        if mult > 0:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def select(\n",
        "        self,\n",
        "        ids=None,\n",
        "        key_extractor=None,\n",
        "        second_key_extractor=None,\n",
        "        return_keys=False, interpolation=False\n",
        "    ):\n",
        "        if ids is None:\n",
        "            ids = self.data.keys()\n",
        "        elif isinstance(ids, int):\n",
        "            ids = [(i, j) for i in set(x[0] for x in self.data.keys())\n",
        "                   for j in range(ids)]\n",
        "        ids = list(sorted(ids))\n",
        "        ids_length = len(ids)\n",
        "        id_set = set(ids)\n",
        "        sample_keys = collections.defaultdict(list)\n",
        "        print(f'Selecting Samples from IDs: {ids}')\n",
        "        n_examples = len(self.data[ids[0]])\n",
        "\n",
        "        selected_examples = list()\n",
        "        # 500 examples, where if we have 20 in the id set, we look at each id at self.data[id][length = 500]\n",
        "        for i in range(n_examples):\n",
        "            print(i)\n",
        "            max_key = None\n",
        "            selected_item = None\n",
        "            for idx in id_set:\n",
        "                item = self.data[idx][i]\n",
        "\n",
        "                first_keys = list()\n",
        "                for grndtruth_idx in ids:\n",
        "                    # i can be up to 500 and grndtruth_idx is the hyperparameter we choose\n",
        "                    grndtruth_item = self.data[grndtruth_idx][i]\n",
        "\n",
        "                    key = key_extractor(item, grndtruth_item)\n",
        "                    first_keys.append(key)\n",
        "                # first key is the number that match with it in the sample (up to 20 etc. ) and second value is the log prob\n",
        "                first_key = sum(first_keys)\n",
        "                second_key = second_key_extractor(\n",
        "                    item) if second_key_extractor is not None else 0\n",
        "                current_key = (first_key, second_key)\n",
        "                item['mbr_key'] = current_key\n",
        "\n",
        "                # create interpolation value which are the values normalized from 0 to 1\n",
        "                item['interpolation'] = np.array(\n",
        "                    [item['bleu'], first_key/ids_length, np.exp(item['avg_logprob'])])\n",
        "                if interpolation:\n",
        "\n",
        "                    # print(len(item['trg_prediction']))\n",
        "                    # print(len(item['reference']))\n",
        "                   \n",
        "                    #item['ROUGE'] = scores\n",
        "                    current_key = (item['interpolation'],)\n",
        "                    # now need to write the case where interpolation = true\n",
        "                    sample_keys[idx].append(current_key)\n",
        "                    if max_key is None or self.greater(current_key[0], max_key[0]):\n",
        "                        max_key = current_key\n",
        "                        selected_item = item\n",
        "                else:\n",
        "                    sample_keys[idx].append(current_key)\n",
        "                    # should try ranking system but must ensure that rank 1 is actually given as n = size\n",
        "                    if max_key is None or current_key > max_key:\n",
        "                        max_key = current_key\n",
        "                        selected_item = item\n",
        "            assert selected_item is not None\n",
        "            selected_examples.append(selected_item)\n",
        "\n",
        "        if return_keys:\n",
        "            return selected_examples, sample_keys\n",
        "        else:\n",
        "            return selected_examples\n",
        "\n",
        "\n",
        "class ExecutionBasedIntraMultiSampleSelector(IntraMultiSampleSelector):\n",
        "    def __init__(self, paths, split='dev', execution_type=None):\n",
        "        super().__init__(paths, split=split)\n",
        "        self.execution_type = execution_type\n",
        "        for i, path in enumerate(self.paths):\n",
        "            if execution_type == 'mbpp':\n",
        "                execute_mbpp_google_folder(path)\n",
        "            else:\n",
        "                raise Exception(\n",
        "                    f'Execution type {execution_type} not supported.')\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.exec.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.exec.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result'] = execution_result\n",
        "                idx += 1\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.execfull.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.execfull.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result_full'] = execution_result\n",
        "                idx += 1\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.exec.codexcases.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.exec.codexcases.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result_codexexec'] = execution_result\n",
        "                idx += 1\n",
        "            idx = 0\n",
        "            while os.path.exists(f'{path}/{split}-{idx}.execfullpass.pkl'):\n",
        "                for j, execution_result in enumerate(pickle.load(open(f'{path}/{split}-{idx}.execfullpass.pkl', 'rb'))):\n",
        "                    self.data[i, idx][j]['execution_result_full_pass'] = execution_result\n",
        "                idx += 1\n",
        "\n",
        "\n",
        "\"\"\"equivalence checking functions\"\"\"\n",
        "# base equavalence checking function\n",
        "\n",
        "\n",
        "def single_exec_result_matching(exec_x, exec_y, good_execution_result):\n",
        "    try:\n",
        "        if exec_x[0] == good_execution_result and exec_y[0] == good_execution_result and exec_x[1] == exec_y[1]:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# first assertion call matching\n",
        "def execution_selection_function(x, y, good_execution_result=0):\n",
        "    exec_x, exec_y = x['execution_result'], y['execution_result']\n",
        "    return single_exec_result_matching(exec_x, exec_y, good_execution_result)\n",
        "\n",
        "\n",
        "# just executability checking\n",
        "def executability_selection_function(x, good_execution_result=0):\n",
        "    exec_res = x['execution_result']\n",
        "    return exec_res[0] == good_execution_result\n",
        "\n",
        "\n",
        "def bleu_selection_function(x, y):\n",
        "    return sentence_bleu([[ch for ch in x['trg_prediction']]], [ch for ch in y['trg_prediction']])\n",
        "\n",
        "\n",
        "def token_bleu_selection_function(x, y):\n",
        "    return sentence_bleu([x['trg_prediction'].split()], y['trg_prediction'].split())\n",
        "\n",
        "\n",
        "def bash_execution_tokenbleu_selection_function(x, y):\n",
        "    if not x['executable'] or not y['executable']:\n",
        "        return 0\n",
        "    x = x['trg_prediction_splitted']\n",
        "    y = y['trg_prediction_splitted']\n",
        "    return sentence_bleu([x], y)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    select and evaluate a group in batch\n",
        "    required keys:\n",
        "        data_split: 'train', 'dev' or 'test'\n",
        "        temperature: 0.1 .. 1.0\n",
        "        criterion: 'mbr_exec' ... see full options in the function\n",
        "        data_path: root data path for the task\n",
        "        n_samples: number of candidates\n",
        "        rand_seed: random seed for one experiment\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def select_mbpp(args, return_selected=False, return_selector=False):\n",
        "    data_split, temperature, criterion, data_path, n_samples, rand_seed = args\n",
        "    mbpp_good_execution_result = 0\n",
        "    data_path = f'{data_path}/seed-*/**/*-{temperature}/'\n",
        "    secondary_key_function = None\n",
        "    interpolation = False\n",
        "    if criterion == 'mbr_exec':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')\n",
        "\n",
        "        def sample_selection_function(x, y): return execution_selection_function(\n",
        "            x, y, mbpp_good_execution_result)\n",
        "\n",
        "        def secondary_key_function(x): return x['sum_logprob']\n",
        "    elif criterion == 'interpolation_mbr_exec':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')\n",
        "\n",
        "        def sample_selection_function(x, y): return execution_selection_function(\n",
        "            x, y, mbpp_good_execution_result)  # this can change because this is just mbr based on execution result -> add new ones that use different functions\n",
        "        interpolation = True\n",
        "\n",
        "    elif criterion == 'logprob':\n",
        "        selector = ExecutionBasedMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "\n",
        "        def sample_selection_function(x): return x['sum_logprob']\n",
        "    elif criterion == 'avg_logprob':\n",
        "        selector = ExecutionBasedMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "\n",
        "        def sample_selection_function(x): return x['avg_logprob']\n",
        "    elif criterion == 'mbr_bleu':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "\n",
        "        def sample_selection_function(\n",
        "            x, y): return bleu_selection_function(x, y)\n",
        "    elif criterion == 'mbr_tokenbleu':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "\n",
        "        def sample_selection_function(\n",
        "            x, y): return token_bleu_selection_function(x, y)\n",
        "    elif criterion == 'executability-logprob':\n",
        "        selector = ExecutionBasedMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')\n",
        "\n",
        "        def sample_selection_function(x): return (executability_selection_function(\n",
        "            x, mbpp_good_execution_result), x['sum_logprob'])\n",
        "    elif criterion == 'executability-avglogprob':\n",
        "        selector = ExecutionBasedMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')\n",
        "\n",
        "        def sample_selection_function(x): return (executability_selection_function(\n",
        "            x, mbpp_good_execution_result), x['avg_logprob'])\n",
        "    elif criterion == 'executability-mbr_bleu':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "\n",
        "        def sample_selection_function(x, y): return bleu_selection_function(x, y) * (1 - x['execution_result'][0]) * \\\n",
        "            (1 - y['execution_result'][0])\n",
        "    elif criterion == 'executability-mbr_tokenbleu':\n",
        "        selector = ExecutionBasedIntraMultiSampleSelector(\n",
        "            data_path, data_split, 'mbpp')  # pre-execution for faster evaluation\n",
        "        def sample_selection_function(x, y): return token_bleu_selection_function(x, y) * (1 - x['execution_result'][0]) * \\\n",
        "            (1 - y['execution_result'][0])\n",
        "    else:\n",
        "        raise ValueError(f'Unknown criterion: {criterion}')\n",
        "    id_keys = list(selector.data.keys())\n",
        "    random.seed(rand_seed)\n",
        "    ids = random.sample(id_keys, n_samples)\n",
        "\n",
        "    if secondary_key_function is not None:\n",
        "        selected = selector.select(\n",
        "            ids, sample_selection_function, secondary_key_function, interpolation=interpolation)\n",
        "    else:\n",
        "        selected = selector.select(\n",
        "            ids, sample_selection_function, interpolation=interpolation)\n",
        "    if return_selector:\n",
        "        return selector\n",
        "    elif return_selected:\n",
        "        return selected\n",
        "    else:\n",
        "\n",
        "        result = evaluate_google_mbpp(selected, 'data/mbpp/mbpp.jsonl', 'test')\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv0yAbhsY_kA",
        "outputId": "1a1e5a3a-97a9-4ca7-8a22-d64b40e6a658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMBjJYaoY144",
        "outputId": "7f7a0512-86d7-4a6d-c6d4-ed6059a1fb02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey\n",
            "<__main__.MBPPGoogleDataset object at 0x7f7d5435a0e0>\n",
            "/content\n",
            "/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/seed-1/3-shot/sample-0.9/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [03:18<00:00,  2.52it/s]\n",
            "100%|██████████| 500/500 [03:45<00:00,  2.22it/s]\n",
            "100%|██████████| 500/500 [04:06<00:00,  2.03it/s]\n",
            "100%|██████████| 500/500 [03:30<00:00,  2.37it/s]\n",
            "100%|██████████| 500/500 [03:58<00:00,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey\n",
            "<__main__.MBPPGoogleDataset object at 0x7f7d1db47130>\n",
            "/content\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/seed-2/3-shot/sample-0.9/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 34/34 [00:03<00:00,  9.17it/s]\n",
            "100%|██████████| 32/32 [00:03<00:00,  9.05it/s]\n",
            "100%|██████████| 500/500 [01:25<00:00,  5.83it/s]\n",
            "100%|██████████| 34/34 [00:10<00:00,  3.38it/s]\n",
            "100%|██████████| 32/32 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 500/500 [05:02<00:00,  1.65it/s]\n",
            "100%|██████████| 34/34 [00:10<00:00,  3.22it/s]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.75it/s]\n",
            "100%|██████████| 500/500 [05:08<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey\n",
            "<__main__.MBPPGoogleDataset object at 0x7f7d1bb92f20>\n",
            "/content\n",
            "/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/seed-3/3-shot/sample-0.9/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 192/192 [00:37<00:00,  5.06it/s]\n",
            "100%|██████████| 192/192 [01:36<00:00,  1.98it/s]\n",
            "100%|██████████| 192/192 [01:39<00:00,  1.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting Samples from IDs: [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0)]\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-239bc1b4fdee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m select_mbpp(('test', 0.9, 'mbr_exec',\n\u001b[0m\u001b[1;32m      2\u001b[0m             '/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/',5 , 0))\n",
            "\u001b[0;32m<ipython-input-3-3967b347deb7>\u001b[0m in \u001b[0;36mselect_mbpp\u001b[0;34m(args, return_selected, return_selector)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msecondary_key_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         selected = selector.select(\n\u001b[0m\u001b[1;32m    366\u001b[0m             ids, sample_selection_function, secondary_key_function, interpolation=interpolation)\n\u001b[1;32m    367\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-3967b347deb7>\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, ids, key_extractor, second_key_extractor, return_keys, interpolation)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mgrndtruth_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# i can be up to 500 and grndtruth_idx is the hyperparameter we choose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mgrndtruth_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrndtruth_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrndtruth_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "select_mbpp(('test', 0.9, 'mbr_exec',\n",
        "            '/content/drive/Shareddrives/COS484FinalProject/data/mbr-2B/mbpp/',5 , 0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}